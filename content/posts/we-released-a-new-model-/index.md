---
title: "We Released a New Model"
date: 2024-08-24T14:48:54+07:00
draft: false
tags: [ai]
categories: []
images: [images/Llama3s.webp]
---
Dated back to this post [Multi Modal Tokenizing With Chameleon](../multi-modal-tokenizing-with-chameleon/). I have worked with my team at [HomeBrew Research](https://homebrew.ltd/) to make something. We wanted to give the community something new and not simply a replicate of Chameleon (vision modality).

By that, we decided to work on a model that can do sound, that you can talk to it, that you can give commands to it. A Llama model that can listen!

{{< youtube nfBElfRhitU >}}
"What is the color of the sky?"

We proudly present the result, a working llama3,1 checkpoint (that we call llama3-s) and have ability to listen to you!
[Announcement Blog](https://homebrew.ltd/blog/llama3-just-got-ears)

If you don't have the time to skim through the blog post, you can also directly use the demo here:
- https://huggingface.co/spaces/jan-hq/Llama3.1-s-v0.2

Hope our effort has brought you some joy and fun (because this is a project of passion)
